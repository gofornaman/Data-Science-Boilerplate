<html>
<head>
  <title>Preparation 10X</title>
  <basefont face="Segoe UI" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="Evernote Windows/308292 (en-US, DDL); Windows/10.0.0 (Win64);"/>
  <style>
    body, td {
      font-family: Segoe UI;
      font-size: 10pt;
    }
  </style>
</head>
<body>
<a name="474"/>
<h1>Preparation 10X</h1>

<div>
<span><div><div><br/></div><ol><li><div>Mean, median, mode </div><div>- Mean is the average</div><div>- Median is the middle value</div><div>- Mode is the most repeated value</div></li></ol><div><br/></div><div>Predictive Lead Classification:</div><ul><li><div>Multi class classification technique</div></li><li><div><span style="font-weight: bold;">Decision Tree (Tree based Modeling):</span></div></li><ul><li><div>They map non linear relationships quite well (change in X wont bring about change in Y)</div></li><li><div>They can solve both classification &amp; regression problems</div></li><li><div>Works for both categorical and continuous var</div></li><li><div><span style="font-weight: bold;">Best method to identify most significant var / feature importance</span></div></li><li><div><span style="font-weight: bold;">Basically we split the sample into two or more homogeneous sets based on most significant splitter/ differentiator in input var</span></div></li><li><div>Core objective of a decision tree is to split sample which creates best homogeneous set</div></li><li><div>How to identify the var and the split? To do this DT use various algos </div></li><li><div>Terms: Root node, Decision node, Terminal node, Splitting,Pruning </div></li><li><div>Regression trees:  the value obtained by terminal nodes is the <span style="font-weight: bold;">mean</span> response of observations falling in that region, we'll make its prediction with mean value</div></li><li><div>Classification trees: the value obtained by terminal nodes is the <span style="font-weight: bold;">mode</span> response of observations falling in that region, we'll make its prediction with mode value </div></li><li><div>Recursive binary splitting, a greedy top down approach</div></li><li><div>This splitting process is continued until a user defined stopping criteria is reached</div></li><li><div>Pruning is one of the technique used tackle overfitting</div></li><li><div><span style="font-weight: bold;">How does the tree decide where to split? - </span>Decision tree splits the nodes on all available variables and then selects the split which results in most homogeneous sub-nodes.</div><div>Four most commonly used algorithms</div></li><ul><li><div>Gini Index:</div></li><ul><li><div>It works with categorical target var - success or failure</div></li><li><div>It performs only binary splits</div></li><li><div>Higher the value of Gini, higher the homogenity</div></li><li><div>CART uses Gini</div></li><li><div>Calculate Gini for sub-nodes, using formula sum of square of probability for success and failure (p^2+q^2).</div></li><li><div>Calculate Gini for split using weighted Gini score of each node of that split</div><div><br/></div></li></ul><li><div>Chi Squared:</div></li><ul><li><div>It is an algo to find statistical significance between sub nodes and parent nodes</div></li><li><div>Works with target var - success or failure</div></li><li><div>Can do more than 2 splits</div></li><li><div>Higher the value of Chi-Square higher the statistical significance of differences between sub-node and Parent node.</div></li><li><div>Chi-square = ((Actual – Expected)^2 / Expected)^1/2</div></li><li><div>CHAID uses Chi Squared algo</div><div><br/></div></li></ul><li><div>Information Gain:</div></li><ul><li><div>Entropy is a measure to define degree of disorganization</div></li><li><div>Sample is completely homogeneous, then entropy is 0</div></li><li><div>Sample is 50-50 divided then entropy is 1</div></li><li><div>The lesser the entropy, the better it is.</div><div><br/></div></li></ul><li><div>Reduction in variance:</div></li><ul><li><div>Reduction in variance is an algorithm used for continuous target variables (regression problems).</div></li><li><div>The split with lower variance is selected as the criteria to split the population</div><div><br/></div></li></ul></ul><li><div><span style="font-weight: bold;">How to avoid overfitting? </span> Overfitting is one of the key challenges faced while modeling decision trees. If there is no limit set of a decision tree, it will give you 100% accuracy on training set because in the worse case it will end up making 1 leaf for each observation.</div></li><ul><li><div>Setting constraints on tree size</div></li><li><div>Pruning - It simply removes the nodes which add little predictive power for the problem in hand.</div><div><br/></div><div><br/></div></li></ul></ul><li><div><span style="font-weight: bold;">Ensemble models:</span></div></li><ul><li><div><span style="font-weight: bold;">Bias &amp; Variance </span></div><div><span style="font-weight: bold;">- </span> Bias means ‘how much on an average are the predicted values different from the actual value.’</div><div>-  Variance means, ‘how different will the predictions of the model be at the same point if different samples are taken from the same population’.</div><div>-  Normally, as you increase the complexity of your model, you will see a reduction in prediction error due to lower bias in the model. As you continue to make your model more complex, you end up over-fitting your model and your model will start suffering from high variance.</div><div>- Bias Variance Trade - Off</div><div><br/></div></li><li><div><span style="font-weight: bold;">What is Bagging?</span></div><div><span style="font-weight: bold;">-</span> Bagging is a technique used to reduce variance of our predictions by combining the results of multiple classifiers modeled on different sub samples of the same data</div><div>-  The predictions of all the classifiers are combined using a mean, median or mode value depending on the problem at hand.</div></li><ul><li><div><span style="font-weight: bold;">Random Forest </span></div></li><ul><li><div>Its a prime example of bagging technique. End to end solution</div></li><li><div>Divides into sample and run classifiers and combines output</div></li><li><div>To classify a new object based on attributes, each tree gives a classification and we say the tree “votes” for that class</div></li><li><div>there is no pruning</div></li><li><div>feature importance</div></li><li><div>missing values, outliers, imbalanced datasets, unsupervised</div></li><li><div>If a unit can occur one or more times in the sample, then the sample is drawn with replacement</div></li><li><div>they have bootstrap sampling - 1/3 saved for testing called &quot;out of the bag&quot; samples</div><div><br/></div></li></ul></ul><li><div><span style="font-weight: bold;">What is Boosting?</span></div><div><span style="font-weight: bold;">-</span> Boosting converts weak learners to strong learners</div></li><ul><li><div><span style="-en-paragraph:true;">The base learner takes all the distributions and assign equal weight or attention to each observation.</span></div></li><li><div><span style="-en-paragraph:true;">If there is any prediction error caused by first base learning algorithm, then we pay higher attention to observations having prediction error. Then, we apply the next base learning algorithm.</span></div></li><li><div><span style="-en-paragraph:true;">Iterate Step 2 till the limit of base learning algorithm is reached or higher accuracy is achieved.</span></div></li><li><div>Eg - GBM and Xgboost</div><div>- Parameters:</div></li><ul><li><div>learning rate</div></li><li><div>n_estimators -  The number of sequential trees to be modeled (step 2)</div></li><li><div>subsample</div></li><li><div>loss </div></li><li><div>init</div></li><li><div>random_state</div></li><li><div>verbose</div></li><li><div>warm_start</div></li><li><div>presort</div></li></ul></ul><li><div><span style="font-weight: bold;">Bagging V Boosting - </span></div></li><li><div><span style="-en-paragraph:true;">The fundamental difference is, random forest uses bagging technique to make predictions. GBM uses boosting techniques to make predictions.</span></div></li><li><div style="text-align: justify; margin-top: 1em; margin-bottom: 1em;"><span style="-en-paragraph:true;">In bagging technique, a data set is divided into n samples using randomized sampling. Then, using a single learning algorithm a model is build on all samples. Later, the resultant predictions are combined using voting or averaging. Bagging is done is parallel. In boosting, after the first round of predictions, the algorithm weighs misclassified predictions higher, such that they can be corrected in the succeeding round. This sequential process of giving higher weights to misclassified predictions continue until a stopping criterion is reached.</span></div></li><li><div style="text-align: justify; margin-top: 1em; margin-bottom: 1em;"><span style="-en-paragraph:true;">Random forest improves model accuracy by reducing variance (mainly). The trees grown are uncorrelated to maximize the decrease in variance. On the other hand, GBM improves accuracy my reducing both bias and variance in a model.</span></div></li></ul></ul><div><br/></div><ul><li><div><span style="font-weight: bold;">KNN Algorithm :</span></div></li><ul><li><div>Can be used for both classifiaction and regression</div></li><li><div>Based on the value of K, we see the classes of neighbouring observations and subsequently take a vote to assign class to new observation</div></li><li><div>How to choose K? </div><div>- K = 1 , error is always zero</div><div>- Plot the validation error curve, get the point of minima</div></li><li><div>Pseudo code</div></li><ul><li><div>Load the data</div></li><li><div>Init val of K</div></li><li><div>For getting the predicted class, iterate from 1 to total training data points</div></li><ol><li><div>Calc the dist btw test data and each row of training data. Using euclidean dist | cosine | chebyshev</div></li><li><div>sort calc values in ascending order of dist</div></li><li><div>get top k rows from sorted array</div></li><li><div>get the most frequent class </div></li><li><div>return predicted class</div><div><br/></div></li></ol></ul></ul><li><div><span style="font-weight: bold;">NAIVE BAYES</span></div></li><ul><li><div>Very fast - works on bayes theorem of probability to predict the class of unknown dataset</div></li><li><div>assumption - predictors are independent</div></li><li><div><img src="Preparation 10X_files/bayes.png" type="image/png" data-filename="bayes.png"/></div></li><ul><li><div><span style="font-style: italic;">P</span>(<span style="font-style: italic;">c|x</span>) is the posterior probability of <span style="font-style: italic;">class</span> (c, <span style="font-style: italic;">target</span>) given <span style="font-style: italic;">predictor</span> (x, <span style="font-style: italic;">attributes</span>).</div></li><li style="text-align: justify;"><div><span style="font-style: italic;">P</span>(<span style="font-style: italic;">c</span>) is the prior probability of <span style="font-style: italic;">class</span>.</div></li><li style="text-align: justify;"><div><span style="font-style: italic;">P</span>(<span style="font-style: italic;">x|c</span>) is the likelihood which is the probability of <span style="font-style: italic;">predictor</span> given <span style="font-style: italic;">class</span>.</div></li><li><div><span style="font-style: italic;">P</span>(<span style="font-style: italic;">x</span>) is the prior probability of <span style="font-style: italic;">predictor</span>.</div></li></ul><li><div>Eg</div></li><ul><li><div><img src="Preparation 10X_files/Bayes2.png" type="image/png" data-filename="Bayes2.png"/></div></li><li><div>More useful for multi class classification</div></li><li><div>performs well in cat and not numerical. assumes bell curve for numerical</div></li><li><div>can be used in NLP recsys, sentiment analysis, text classficiation</div></li><li><div>3 types of NB in sklearn -</div></li><ul><li><div>Gaussian - assumes feature follow normal dist</div></li><li><div>Multinominal - used for discrete counts</div></li><li><div>Bernoulli - useful if features are binary, bag of words</div></li></ul><li><div>Zero frequency (class not in train, occurs in test) - use Laplace correction</div></li><li><div>remove correlated features</div></li><li><div>ensembling wont work, they are used to reduce variance, nb doesnt have variance</div><div><br/></div><div><br/></div></li></ul></ul><li><div><span style="font-weight: bold;">LINEAR REGRESSION:</span></div></li><ul><li><div>to predict continuous vars</div></li><li><div>regression line -  we establish relationship between independent and dependent variables by fitting a best line</div></li><li><div>equation - Y = a * X + b</div></li><ul><li><div>Y – Dependent Variable</div></li><li style="text-align: justify;"><div>a – Slope</div></li><li style="text-align: justify;"><div>X – Independent variable</div></li><li><div>b – Intercept</div></li></ul><li><div>These coefficients a and b are derived based on minimizing the sum of squared difference of distance between data points and regression line.</div><div><br/></div></li></ul><li><div><span style="font-weight: bold;">LOGISTIC REGRESSION:</span></div></li><ul><li><div>In simple words, it predicts the probability of occurrence of an event by fitting data to a <a href="https://en.wikipedia.org/wiki/Logistic_function">logit function</a>.</div></li><li><div>Since, it predicts the probability, its output values lies between 0 and 1</div></li><li><div>odds= p/ (1-p) = probability of event occurrence / probability of not event occurrence</div></li><li><div>ln(odds) = ln(p/(1-p))</div></li><li><div>logit(p) = ln(p/(1-p)) = b0+b1X1+b2X2+b3X3....+bkXk</div></li><li><div>Above, p is the probability of presence of the characteristic of interest. It chooses parameters that maximize the likelihood of observing the sample values rather than that minimize the sum of squared errors (like in ordinary regression).</div></li><li><div>Why log?  this is one of the best mathematical way to replicate a step function.</div><div><br/></div></li></ul><li><div><span style="font-weight: bold;">SVM:</span></div></li><ul><li><div>In this algorithm, we plot each data item as a point in n-dimensional space (where n is number of features you have) with the value of each feature being the value of a particular coordinate.</div></li><li><div>Support Vectors are simply the co-ordinates of individual observation.</div></li><li><div>A Support Vector Machine (<span style="font-weight: bold;">SVM</span>) performs classification by finding the <span style="font-weight: bold;">hyperplane</span> that maximizes the margin between the two classes. The vectors (cases) that define the <span style="font-weight: bold;">hyperplane</span> are the support vectors. Algorithm. Define an optimal <span style="font-weight: bold;">hyperplane</span>: maximize margin.</div><div><br/></div></li></ul><li><div><span style="font-weight: bold;">K-MEANS:</span></div></li><ul><li><div>Two types: Hard cluster (data points will be belong to a group) and Soft cluster (probability of a data point belonging to a group)</div></li><ul><li><div>Connectivity, Centroid, Distribution, Density </div></li></ul><li><div>Kmeans is an interactive clustering algo that aims to find local maxima in each iteration</div></li><ul><li><div>Specify the desired number of clusters K</div></li><li><div>Randomly assign each data point to a cluster</div></li><li><div>Compute cluster centroids : The centroid of data points in the red cluster is shown using red cross and those in grey cluster using grey cross.</div></li><li><div>Re-assign each point to the closest cluster centroid</div></li><li><div>Re-compute cluster centroids</div></li><li><div>Repeat steps 4 and 5 until no improvements are possible : Similarly, we’ll repeat the 4<span style="vertical-align: super; font-size: smaller; font-size: smaller;">th</span> and 5<span style="vertical-align: super; font-size: smaller; font-size: smaller;">th</span> steps until we’ll reach global optima. When there will be no further switching of data points between two clusters for two successive repeats. It will mark the termination of the algorithm if not explicitly mentioned</div></li><li><div><span style="font-weight: bold;">how to calc K? </span> We know that as the number of cluster increases, this value keeps on decreasing but if you plot the result you may see that the sum of squared distance decreases sharply up to some value of k, and then much more slowly after that. Here, we can find the optimum number of cluster. (this is called as WCSS (Within cluster sum of square) <b>Elbow method</b></div><div><b><br/></b></div></li></ul><li><div><span style="-en-paragraph:true;">The objective of any clustering algorithm is to ensure that the distance between datapoints in a cluster is very low compared to the distance between 2 clusters. In other words, members of a group are very similar, and members of different groups are extremely dissimilar</span></div></li><li><div style="margin-top: 1em; margin-bottom: 1em;"><span style="-en-paragraph:true;">The mathematics behind clustering, in very simple terms involves minimizing the sum of square of distances between the cluster centroid and its associated data points</span></div></li><li><div style="margin-top: 1em; margin-bottom: 1em;"><b>Silhouette coefficients</b> near +1 indicate that the sample is far away from the neighboring clusters. A value of 0 indicates that the sample is on or very close to the decision boundary between two neighboring clusters and negative values indicate that those samples might have been assigned to the wrong cluster.<br/></div></li></ul><li><div><span style="font-weight: bold;">ARIMA:</span></div></li><ul><ul><li><div>it is diff than regression bcos it takes relative past values into account as well</div></li><li><div>methods:</div></li><ul><li><div>naive approach - basically linear trend line</div></li><li><div>simple avg - next value is taken as avg of all prev values</div></li><li><div>moving avg - NOT all prev values avg is taken,  the average of ‘n’ previous points is taken to be the predicted value.</div></li><li><div>weighted moving avg -  A weighted moving average is a moving average where the past ‘n’ values are given different weights.</div></li><li><div>simple exp smoothing -  larger weights are assigned to more recent observations than to observations from the distant past.</div></li><li><div>holt's linear trend - trend of dataset is taken into acc</div></li><li><div>holt's winter model - both trend &amp; seasonality</div></li><li><div>arima - describes correlation between data points  and takes into account the difference of the values</div></li></ul><li><div>ARIMA -</div></li><ul><li><div><span style="font-weight: bold;">Auto-Regressive Integrated Moving Averages</span></div></li><li><div>two assumptions:</div></li><ul><li><div>The data series is stationary, which means that the mean and variance should not vary with time. A series can be made stationary by using log transformation or differencing the series.</div></li><li><div>The data provided as input must be a univariate series, since arima uses the past values to predict the future values.</div></li></ul><li><div>steps:</div></li><ul><li><div><span style="font-weight: bold;">Load the data:</span> The first step for model building is of course to load the dataset</div></li><li><div><span style="font-weight: bold;">Preprocessing:</span> Depending on the dataset, the steps of preprocessing will be defined. This will include creating timestamps, converting the dtype of date/time column, making the series univariate, etc.</div></li><li><div><span style="font-weight: bold;">Make series stationary:</span> In order to satisfy the assumption, it is necessary to make the series stationary. This would include checking the stationarity of the series and performing required transformations</div></li><li><div><span style="font-weight: bold;">Determine d value:</span> For making the series stationary, the number of times the difference operation was performed will be taken as the d value</div></li><li><div><span style="font-weight: bold;">Create ACF and PACF plots:</span> This is the most important step in ARIMA implementation. ACF PACF plots are used to determine the input parameters for our ARIMA model</div></li><li><div><span style="font-weight: bold;">Determine the p and q values:</span> Read the values of p and q from the plots in the previous step</div></li><li><div><span style="font-weight: bold;">Fit ARIMA model:</span> Using the processed data and parameter values we calculated from the previous steps, fit the ARIMA model</div></li><li><div><span style="font-weight: bold;">Predict values on validation set:</span> Predict the future values</div></li><li><div><span style="font-weight: bold;">Calculate RMSE:</span> To check the performance of the model, check the RMSE value using the predictions and actual values on the validation set</div></li></ul><li><div>used auto arima</div></li></ul></ul></ul></ul><div><br/></div><div><br/></div><ul><li><div><span style="font-weight: bold;">How to avoid overfitting?</span></div></li><ul><li><div>Cross validation -  But for keeping lower variance a higher fold cross validation is preferred.</div></li><li><div>Early stopping</div></li><li><div>Pruning -  Pruning is used extensively while building CART models. It simply removes the nodes which add little predictive power for the problem in hand.</div></li><li><div>Regularization -  introduces a cost term for bringing in more features with the objective function. Hence, it tries to push the coefficients for many variables to zero and hence reduce cost term.</div><div>-  optimization might simply overfit the equation if x1 , x2 , x3  (independent variables ) are too many in numbers. Hence we introduce a new penalty term in our objective function to find the estimates of co-efficient.</div></li><li><div><span style="font-weight: bold;">Regularization becomes necessary when the model begins to ovefit / underfit. This technique introduces a cost term for bringing in more features with the objective function. Hence, it tries to push the coefficients for many variables to zero and hence reduce cost term. This helps to reduce model complexity so that the model can become better at predicting (generalizing).</span></div><div><br/></div></li></ul><li><div><span style="font-weight: bold;">Evaluation metrics:</span></div></li><ul><li><div>Precision/Specificity: how many selected instances are relevant.</div></li><li><div>Recall/Sensitivity: how many relevant instances are selected.</div></li><li><div>F1 score: harmonic mean of precision and recall.</div></li><li><div>MCC: correlation coefficient between the observed and predicted binary classifications.</div></li><li><div>AUC: relation between true-positive rate and false positive rate.</div><div><br/></div></li></ul><li><div><span style="font-weight: bold;">Handling imbalanced dataset:</span></div></li><ul><li><div>Under / Over sampling </div><div>-  Under-sampling balances the dataset by reducing the size of the abundant class</div><div>-  Rather than getting rid of abundant samples, new rare samples are generated by using e.g. repetition, bootstrapping or SMOTE</div></li><li><div>Using K-Fold Validation</div></li><li><div>Resample with different ratios</div></li><li><div>Ensemble different resampled datasets</div></li><li><div>Cluster the abundant class -  An elegant approach was proposed by Sergey on Quora [2]. Instead of relying on random samples to cover the variety of the training samples, he suggests clustering the abundant class in r groups, with r being the number of cases in r. For each group, only the medoid (centre of cluster) is kept. The model is then trained with the rare class and the medoids only.</div></li></ul></ul><div><br/></div><ul><li><div><span style="font-weight: bold;">Difference between L1 &amp; L2 as loss function &amp; regularization</span> <a href="http://www.chioka.in/differences-between-l1-and-l2-as-loss-function-and-regularization/" style="font-style: italic;">(Link to article)</a></div></li><ul><li><div><span style="font-style: italic; font-weight: bold;">L1-norm &amp; L2-norm as a loss function -</span></div></li><ul><li><div>L1-norm are also known as <span style="font-style: italic;">least absolute deviation, least absolute errors</span></div></li><li><div>It is basically minimizing sum of absolute differences between target value and estimated values</div></li><li><div>L2-norm also know as <span style="font-style: italic;">least squares error</span></div></li><li><div>It is basically minimizing sum of square of differences between target value and estimated values</div></li></ul></ul></ul><div style="text-align: center;"><img src="Preparation 10X_files/Image.png" type="image/png" data-filename="Image.png"/></div><div><br/></div><div><br/></div><ul><li><div><span style="font-weight: bold;">What is Precision &amp; Recall?</span></div></li><ul><li><div><span style="font-weight: bold;">Precision</span> - High precision means that the model does not give many &quot;False Positives&quot;.</div></li><li><div><span style="font-weight: bold;">Recall</span> High Recall means that model has a very low proportion of &quot;False Negatives&quot;.</div></li><li><div><span style="font-weight: bold;">F1 Score </span>The F1 Score is a balance between Precision and Recall, this a great measure for overall accuracy.</div></li></ul></ul><div style="margin-top: 1em; margin-bottom: 1em;"><span style="-en-paragraph:true;">True Positive: This is a good prediction, our model predicted that the customer was going to churn (emitted a 1) and the customer did in reality churn (churn=1).</span></div><div style="margin-top: 1em; margin-bottom: 1em;"><span style="-en-paragraph:true;">False Positive: This is an incorrect prediction, our model predicted that our customer churned ( emitted a 1), however it turns out that customer did not in fact churn (churn=0)</span></div><div style="margin-top: 1em; margin-bottom: 1em;"><span style="-en-paragraph:true;">True Negative : This is again a correct prediction, our model said that the customer was not going to churn ( it emitted a 0) and this turned out to be correct in the real world ( churn was equal to 0)</span></div><div style="margin-top: 1em; margin-bottom: 1em;"><span style="-en-paragraph:true;">False Negative: Again, this is an incorrect prediction, but of a different kind. Here our model predicted that the customer was not going to churn (emitted a 0), but lo and behold, in reality our customer did in fact leave the company (churn=1)</span></div><ul><li><div style="margin-top: 1em; margin-bottom: 1em;"><span style="-en-paragraph:true;"><span style="font-weight: bold;">Type I error is committed when the null hypothesis is true and we reject it, also known as a ‘False Positive’. Type II error is committed when the null hypothesis is false and we accept it, also known as ‘False Negative’.</span></span></div></li><li><div style="text-align: justify; margin-top: 1em; margin-bottom: 1em;"><span style="-en-paragraph:true;">In the context of confusion matrix, we can say Type I error occurs when we classify a value as positive (1) when it is actually negative (0). Type II error occurs when we classify a value as negative (0) when it is actually positive(1).</span></div></li></ul><div style="margin-top: 1em; margin-bottom: 1em;"><div><span style="font-weight: bold;">How to calc accuracy of regression model?</span></div><div>R2, MAE (Mean absolute error), Explained Variance</div><div>We want R2 and EVS to be close to 1.0 and MAE to be close to 0</div><div><br/></div><ul><li><div><br/></div></li></ul></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div>Resume based questions</div><div>ML questions</div><div>SQL</div><div>Stats questions</div><div>Probability questions</div><div>Algorithms</div><div>Puzzles</div><div>Guestimates</div><div>Case study</div><div><br/></div><div><br/></div><div><br/></div></div><div><br/></div></span>
</div></body></html> 